# BigDataPryFinal

## ğŸ“Š Proyecto Final Big Data â€“ Pipeline End-to-End con PySpark

Este proyecto implementa un **sistema integral End-to-End de Big Data** que cubre las fases de **ingesta, procesamiento optimizado y visualizaciÃ³n**, utilizando **Apache Spark (PySpark)** como motor principal.

El caso de estudio corresponde al anÃ¡lisis de datos histÃ³ricos de emergencias (LÃ­nea 123 â€“ BogotÃ¡), procesando grandes volÃºmenes de informaciÃ³n de manera eficiente y escalable.  
El proyecto demuestra buenas prÃ¡cticas de **ingenierÃ­a de datos**, **optimizaciÃ³n en Spark** y **portabilidad a entornos empresariales**.

---

## ğŸ¯ Objetivo del Proyecto

- Procesar hasta **24 meses de datos histÃ³ricos** sin errores de memoria.
- Construir un pipeline escalable usando Spark.
- Aplicar optimizaciones reales (broadcast, particionamiento, cache).
- Validar la ejecuciÃ³n tanto en **Google Colab** como en **Databricks**.
- Generar datasets optimizados para visualizaciÃ³n.

---

## ğŸš€ EjecuciÃ³n del Proyecto

### ğŸ’» EjecuciÃ³n en Google Colab

#### 1ï¸âƒ£ Clonar el repositorio

```bash
git clone https://github.com/milo1409/BigDataPryFinal.git
cd BigDataPryFinal
```

#### 2ï¸âƒ£ Instalar dependencias

```python
!pip install -r requirements.txt
```

#### 3ï¸âƒ£ Ejecutar el notebook principal

```text
notebooks/PipeLinePlay.ipynb
```

El pipeline ejecuta:
- Ingesta de datos  
- Limpieza y estandarizaciÃ³n  
- Procesamiento distribuido con Spark  
- GeneraciÃ³n de datasets optimizados para visualizaciÃ³n  

---

### â˜ï¸ EjecuciÃ³n en Databricks (PoC)

1. Importar el notebook `PipeLinePlay.ipynb` al Workspace de Databricks.
2. Adjuntar un **cluster activo**.
3. Ejecutar el pipeline completo.
4. Capturar evidencia visual de la ejecuciÃ³n exitosa.

Este paso valida la **portabilidad del pipeline a un entorno empresarial**.

---

## ğŸ“¦ InstalaciÃ³n de Dependencias

```bash
pip install -r requirements.txt
```

Dependencias principales:

- pyspark
- pandas
- numpy
- matplotlib
- plotly
- psutil

---

## âš™ï¸ JustificaciÃ³n TÃ©cnica de las Optimizaciones

### ğŸ”¹ Uso de Broadcast Join

Se utilizÃ³ `broadcast()` para joins entre datasets grandes y pequeÃ±os, evitando operaciones costosas de shuffle y reduciendo tiempos de ejecuciÃ³n.

```python
from pyspark.sql.functions import broadcast
df_resultado = df_grande.join(broadcast(df_pequeno), "clave", "left")
```

---

### ğŸ”¹ Particionamiento de Datos

Se aplicÃ³ `repartition()` sobre columnas clave para mejorar paralelismo y balancear carga.

```python
df = df.repartition(200, "FECHA")
```

En etapas finales se utilizÃ³ `coalesce()`.

---

### ğŸ”¹ Cache y Persistencia

```python
df_filtrado.cache()
```

Evita recomputaciones y mejora el rendimiento general.

---

### ğŸ”¹ Filtrado Temprano y SelecciÃ³n de Columnas

- ReducciÃ³n del volumen de datos desde etapas iniciales.
- SelecciÃ³n de columnas necesarias para cada proceso.

---

### ğŸ”¹ Ajustes de ConfiguraciÃ³n Spark

```python
spark.conf.set("spark.sql.shuffle.partitions", "200")
```

---

## ğŸ“ˆ Resultados Obtenidos

- Procesamiento exitoso de **24 meses de datos histÃ³ricos**.
- EjecuciÃ³n estable en Google Colab.
- ValidaciÃ³n exitosa en Databricks Community Edition.
- ReducciÃ³n significativa de tiempos de ejecuciÃ³n.

---

## ğŸ—‚ï¸ Estructura del Proyecto

```
BigDataPryFinal/
â”‚
â”œâ”€â”€ config/
â”œâ”€â”€ data/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ PipeLinePlay.ipynb
â”œâ”€â”€ src/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ‘¤ Autor

**AndrÃ©s Porras**  
Proyecto Final â€“ Big Data  
Diciembre 2025

---

## ğŸ“ Notas Finales

Este proyecto demuestra un enfoque profesional de ingenierÃ­a de datos, aplicando optimizaciones reales de Apache Spark y validando su ejecuciÃ³n en entornos acadÃ©micos y empresariales.
