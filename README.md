# BigDataPryFinal

## ğŸ“Š Proyecto Final Big Data â€“ Pipeline End-to-End con PySpark

Este proyecto implementa un **pipeline integral de Big Data** que cubre las fases de **ingesta, procesamiento optimizado y visualizaciÃ³n**, utilizando **Apache Spark (PySpark)** como motor principal.  
El caso de estudio corresponde al anÃ¡lisis de datos histÃ³ricos de emergencias (LÃ­nea 123), procesando grandes volÃºmenes de informaciÃ³n de manera eficiente y escalable.

El desarrollo estÃ¡ orientado a demostrar **buenas prÃ¡cticas de optimizaciÃ³n en Spark**, garantizando ejecuciÃ³n sin errores de memoria incluso con datasets de mÃºltiples meses.

---

## ğŸš€ Instrucciones de Despliegue

### ğŸ› ï¸ Requisitos Previos

Antes de ejecutar el proyecto, asegÃºrate de contar con:

- **Python 3.8 o superior**
- **Java 8 u 11** (requerido por Spark)
- **Apache Spark / PySpark**
- Acceso a uno de los siguientes entornos:
  - Google Colab
  - Databricks Community Edition
  - Ambiente local con Spark configurado

---

### ğŸ“¦ InstalaciÃ³n de LibrerÃ­as

El proyecto utiliza librerÃ­as estÃ¡ndar para procesamiento distribuido y anÃ¡lisis de datos.

#### â¤ InstalaciÃ³n usando `requirements.txt`

```bash
pip install -r requirements.txt
