# BigDataPryFinal

## ğŸ“Š Proyecto Final Big Data â€“ Pipeline End-to-End con PySpark

Este proyecto implementa un **sistema integral End-to-End de Big Data** que cubre las fases de **ingesta, procesamiento optimizado y visualizaciÃ³n**, utilizando **Apache Spark (PySpark)** como motor principal.

El caso de estudio corresponde al anÃ¡lisis de datos histÃ³ricos de emergencias (LÃ­nea 123 â€“ BogotÃ¡), procesando grandes volÃºmenes de informaciÃ³n de manera eficiente y escalable.  
El proyecto demuestra buenas prÃ¡cticas de **ingenierÃ­a de datos**, **optimizaciÃ³n en Spark** y **portabilidad a entornos empresariales**.

---

## ğŸ¯ Objetivo del Proyecto

- Procesar hasta **36 meses de datos histÃ³ricos** sin errores de memoria.
- Construir un pipeline escalable usando Spark.
- Aplicar optimizaciones reales (broadcast, particionamiento, cache).
- Validar la ejecuciÃ³n en **Google Colab**.
- Generar datasets optimizados para visualizaciÃ³n.

---

## ğŸš€ EjecuciÃ³n del Proyecto

### ğŸ’» EjecuciÃ³n en Google Colab

#### 1ï¸âƒ£ Clonar el repositorio

```bash
git clone https://github.com/milo1409/BigDataPryFinal.git
cd BigDataPryFinal
```

#### 2ï¸âƒ£ Instalar dependencias

```python
!pip install -r requirements.txt
```

#### 3ï¸âƒ£ Ejecutar el notebook principal

```text
notebooks/PipeLinePlay.ipynb
```

El pipeline ejecuta:
- Ingesta de datos  
- Limpieza y estandarizaciÃ³n  
- Procesamiento distribuido con Spark  
- GeneraciÃ³n de datasets optimizados para visualizaciÃ³n  

---

### â˜ï¸ EjecuciÃ³n en Databricks (PoC)

1. Importar el notebook `PipeLinePlay.ipynb` al Workspace de Databricks.
2. Adjuntar un **cluster activo**.
3. Ejecutar el pipeline completo.
4. Capturar evidencia visual de la ejecuciÃ³n exitosa en Databricks.

<img width="1913" height="496" alt="image" src="https://github.com/user-attachments/assets/0cb8ab1a-2b13-4782-822e-0f7fc715e9c9" />

<img width="1271" height="699" alt="image" src="https://github.com/user-attachments/assets/3c829228-23c8-4cb9-87b5-2f2656bdc083" />

<img width="1297" height="691" alt="image" src="https://github.com/user-attachments/assets/69a0e581-0a3f-4702-b930-a3d0c941a7e7" />


---

## ğŸ“¦ InstalaciÃ³n de Dependencias

```bash
pip install -r requirements.txt
```

Dependencias principales:

- pyspark
- pandas
- numpy
- matplotlib
- plotly
- psutil

---

## âš™ï¸ JustificaciÃ³n TÃ©cnica de las Optimizaciones

### ğŸ”¹ Uso de Broadcast Join

Se utilizÃ³ `broadcast()` para joins entre datasets grandes y pequeÃ±os Geocodificar las localidades, evitando operaciones costosas de shuffle y reduciendo tiempos de ejecuciÃ³n.

```python
from pyspark.sql.functions import broadcast
df_resultado = df_grande.join(broadcast(df_pequeno), "clave", "left")
```

---

### ğŸ”¹ Particionamiento de Datos

Se aplicÃ³ `repartition()` sobre columnas clave para mejorar paralelismo y balancear carga.

```python
df = df.repartition(200, "FECHA")
```

En etapas finales se utilizÃ³ `coalesce()`.

---

### ğŸ”¹ Cache y Persistencia

```python
df_filtrado.cache()
```

Evita recomputaciones y mejora el rendimiento general.

---

### ğŸ”¹ Filtrado Temprano y SelecciÃ³n de Columnas

- ReducciÃ³n del volumen de datos desde etapas iniciales.
- SelecciÃ³n de columnas necesarias para cada proceso.

---

## ğŸ“ˆ Resultados Obtenidos

- Procesamiento exitoso de **36 meses de datos histÃ³ricos**.
- EjecuciÃ³n estable en Google Colab.
- ValidaciÃ³n en Databricks.
- ReducciÃ³n significativa de tiempos de ejecuciÃ³n.

---
## ğŸ—‚ï¸ Estructura del Proyecto

```
BigDataPryFinal/
â”‚
â”œâ”€â”€ config/                 # Archivos de configuraciÃ³n
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cruda/              # Datos originales descargados
â”‚   â”œâ”€â”€ procesada/          # Datos transformados por Spark
â”‚   â””â”€â”€ dashboard/          # Datos finales para visualizaciÃ³n
â”‚
â”œâ”€â”€ PipeLinePlay.ipynb  # Notebook principal del pipeline
â”‚
â”œâ”€â”€ src/                    # CÃ³digo fuente PySpark
â”œâ”€â”€ utilities/              # Funciones utilitarias
â”œâ”€â”€ requirements.txt        # Dependencias del proyecto
â””â”€â”€ README.md
```



## ğŸ‘¤ Autores

- **Oscar Clavijo**
- **Edward Daniel Porras** 
- **Camilo Andres Porras**
Proyecto Final â€“ Big Data  
Diciembre 2025

---
